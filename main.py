from flask import Flask
import google.generativeai as genai
from telegram import Update
from telegram.ext import ApplicationBuilder, MessageHandler, filters, ContextTypes
import nest_asyncio
import asyncio
import threading
import os

# Ù…ÙØ§ØªÙŠØ­ Ù…Ù† Environment Variables
BOT_TOKEN = os.environ.get("BOT_TOKEN")
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")

# Ø¥Ø¹Ø¯Ø§Ø¯ Gemini
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel("gemini-2.5-flash")

# Ø¥ØµÙ„Ø§Ø­ event loop
nest_asyncio.apply()

# Flask server
web_app = Flask(__name__)

@web_app.route('/')
def home():
    return "ğŸ¤– AI Bot is running!"

def run_flask():
    port = int(os.environ.get("PORT", 10000))  # Render ÙŠØ¹Ø·ÙŠ PORT ØªÙ„Ù‚Ø§Ø¦ÙŠ
    web_app.run(host="0.0.0.0", port=port)

# Ø¨ÙˆØª ØªÙ„ØºØ±Ø§Ù…
async def chat_ai(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_message = update.message.text
    print(f"User: {user_message}")

    try:
        response = model.generate_content(user_message)
        bot_reply = response.text
    except Exception as e:
        bot_reply = f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ: {e}"

    await update.message.reply_text(bot_reply)

# Ø¥Ø¹Ø¯Ø§Ø¯ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¨ÙˆØª
app = ApplicationBuilder().token(BOT_TOKEN).build()
app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, chat_ai))

# ØªØ´ØºÙŠÙ„ Flask server + Ø§Ù„Ø¨ÙˆØª
threading.Thread(target=run_flask).start()

async def run_bot():
    await app.run_polling()

asyncio.run(run_bot())
